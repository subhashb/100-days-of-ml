{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data before cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Cleanup\n",
    "\n",
    "* https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68\n",
    "* https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataset, including generated columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are our columns, again?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# General information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "* https://analyticsindiamag.com/5-ways-handle-missing-values-machine-learning-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin\n",
    "\n",
    "Unfortunately, over 77% of Cabin info is missing in the dataset. Discarding data which does not have cabin data is out of the question. Also, survival may have been affected by which cabin a person was in and consequently which deck they were on, when the Titanic sank. While we could set it to a new value like `U`, a better way would be to analyse the deck structure of RMS Titanic and assign cabins by class.\n",
    "\n",
    "A cursory read-through of how Titanic's cabins were organized in Wikipedia gives the following insights:\n",
    "* A-Deck: It was reserved exclusively for First Class passengers\n",
    "* B-Deck: More First Class passenger accommodations were located here \n",
    "* C-Deck: Crew Cabins\n",
    "* D-Deck: First, Second and Third Class passengers had cabins on this deck\n",
    "* E-Deck: The majority of E-Deck was occupied by Second-Class\n",
    "* F-Deck: Second and Third Class passengers\n",
    "\n",
    "So, let us assign decks based on a passenger's class in the following way:\n",
    "* First Class: Random assignment beteween A and B Decks\n",
    "* Second Class: Random assignment between D and E Decks\n",
    "* Third Class: Random assignment between E, F and G Decks\n",
    "\n",
    "While we are at it, let's also convert values in Cabin column to Decks, because that's a better feature for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cabin(df):\n",
    "    # Convert Cabins to Decks\n",
    "    def convert_to_deck(cabin):\n",
    "        if not pd.isna(cabin):\n",
    "            cabin = cabin[0]\n",
    "        return cabin\n",
    "\n",
    "    df['Deck'] = df['Cabin'].apply(convert_to_deck)\n",
    "    \n",
    "    # Remove the odd value 'T' in Cabin/Deck\n",
    "    df = df[df['Deck'] != 'T']\n",
    "    \n",
    "    # Random assignment of Decks for passengers with no Cabin info\n",
    "    for i, row in df[df['Cabin'].isnull()].iterrows(): \n",
    "        if row['Pclass'] == 1:\n",
    "            df.at[i, 'Deck'] = random.choice(['A', 'B'])\n",
    "        elif row['Pclass'] == 2:\n",
    "            df.at[i, 'Deck'] = random.choice(['D', 'E'])\n",
    "        else:\n",
    "            df.at[i, 'Deck'] = random.choice(['E', 'F', 'G'])\n",
    "            \n",
    "    # Drop cabin from the dataset\n",
    "    df = df.drop('Cabin', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked\n",
    "\n",
    "Most passengers boarded Titanic at Southampton (923, vs. 274 in Cherbourg and 123 in Queenstown). Let's just assign the missing `Embarked` values to `S` for Southampton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_embarked(df):\n",
    "    # Update null values in Embarked to S\n",
    "    df['Embarked'].fillna('S', inplace=True)\n",
    "    \n",
    "    # Also replace Embarked with numeric values\n",
    "    df.loc[df['Embarked'] == 'S', 'Embarked'] = 0\n",
    "    df.loc[df['Embarked'] == 'C', 'Embarked'] = 1\n",
    "    df.loc[df['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "\n",
    "The age of passengers is a very important attribute for our analysis, as Children were among the group of people onboard with a higher chance of survival (others being Women and Upper class). Removing records with no age information (~20% of the dataset) is not an option, neither is replacing the age with mean, median or mode. Let's use the age values we have from the other 80% of data to predict the missing 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_age(df):\n",
    "    # Use Pandas Dataframe Interpolate to fill missing values!\n",
    "    df = df.interpolate()\n",
    "    \n",
    "    # Or take the longer way to predict missing Age values\n",
    "    if df['Age'].isnull().sum() > 0:\n",
    "        linear = LinearRegression()\n",
    "\n",
    "        data_with_null = df[df['Age'].isnull()][['PassengerId', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Age', 'Embarked']]\n",
    "        data_without_null = df[['PassengerId', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Age', 'Embarked']].dropna()\n",
    "\n",
    "        age_train_X = data_without_null.drop('Age', axis=1)\n",
    "        age_train_y = data_without_null['Age']\n",
    "\n",
    "        # FIXME - Does the presence of PassengerId affect fit?\n",
    "        linear.fit(age_train_X, age_train_y)\n",
    "\n",
    "        age_predicted = data_with_null\n",
    "        age_test_X = data_with_null.drop('Age', axis=1)\n",
    "\n",
    "        age_predicted['Age'] = linear.predict(age_test_X)\n",
    "\n",
    "        # https://stackoverflow.com/questions/41773728/pandas-fill-na-with-data-from-another-dataframe-based-on-same-id\n",
    "        df_cleaned = df.set_index(\"PassengerId\").combine_first(age_predicted.set_index(\"PassengerId\")).reset_index()\n",
    "\n",
    "        # Set Negative age to a particular value, say 5 years\n",
    "        df.loc[df['Age'] < 0., 'Age'] = 5\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "* https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/\n",
    "* https://statinfer.com/104-3-5-box-plots-and-outlier-dectection-using-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x11341e630>,\n",
       "  <matplotlib.lines.Line2D at 0x11341eac8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x11341eef0>,\n",
       "  <matplotlib.lines.Line2D at 0x113433358>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x11341e4e0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x113433780>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x113433ba8>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEYRJREFUeJzt3XFslPd9x/HPx+CaYbYAwUMRJjNSaKdWuHV1irJ0f5SmjLSboH+0VadpRRUyMgHUCaQR+KdUmlCrRMlWuuLCUjWdtrZRtypWhRZo2qiasmY1aofbZm1NRAQ0LTYYZxiBnOW7P/zDsy8Gn89nHt+P90s63fN8n9/dfS3hjx9+97vnHBECAOSroegGAABzi6AHgMwR9ACQOYIeADJH0ANA5gh6AMgcQQ8AmSPoASBzBD0AZG5h0Q1I0ooVK6Ktra3oNgCgrpw8eXIwIlqmGzcvgr6trU29vb1FtwEAdcX2q5WMY+oGADJH0ANA5gh6AMgcQQ8AmSPoASBzBD0whY0bN6qhoUG21dDQoI0bNxbdElA1gh4os3HjRh0/flxdXV26fPmyurq6dPz4ccIedWterKMH5pMTJ05o+/bt+tKXviRJ4/fd3d1FtgVUzfPhO2NLpVLwgSnMF7Z1+fJl3XXXXeO14eFhLV26VPPh9wW4wfbJiChNN66iqRvbZ2z32f6J7d5UW277hO1fpftlqW7bX7Ddb/uU7ffO7kcBbi/b2rdv36Tavn37ZLugjoDZmckc/fqIeM+Evx6PSno+ItZKej7tS9KHJK1Nt22SDteqWeB22LBhgw4fPqxHHnlEw8PDeuSRR3T48GFt2LCh6NaAqlQ0dWP7jKRSRAxOqP1C0vsj4jXb90h6ISLeYfvLafvr5eNu9vxM3WC+2bhxo06cOKGIkG1t2LBBzz33XNFtAZNUOnVT6ZuxIem47ZD05Yg4ImnlhPD+jaSVaXuVpLMTHnsu1W4a9MB8Q6gjJ5UG/R9HxHnbvy/phO3/nngwIiL9EaiY7W0am9rRvffeO5OHAgBmoKI5+og4n+4vSPq2pPsl/TZN2SjdX0jDz0taPeHhralW/pxHIqIUEaWWlmkvpwwAqNK0QW+72fbv3tiW9CeSfiqpR9KWNGyLpGfTdo+kT6bVNw9IGr7V/DwAYG5VMnWzUtK309KyhZL+OSL+zfaPJD1je6ukVyV9PI0/JunDkvolXZX0qZp3DQCo2LRBHxGvSHr3FPWLkh6aoh6SdtSkOwDArHGtGwDIHEEPAJkj6AEgcwQ9AGSOoAeAzBH0AJA5gh4AMkfQA0DmCHoAyBxBDwCZI+gBIHMEPQBkjqAHgMwR9ACQOYIeADJH0ANA5gh6AMgcQQ8AmSPoASBzBD0AZI6gB4DMEfQAkDmCHgAyR9ADQOYIegDIHEEPAJkj6AEgcwQ9AGSOoAeAzBH0AJC5ioPe9gLbP7b9nbS/xvZLtvttf9P221K9Ke33p+Ntc9M6AKASMzmj/7Sklyfsf17SkxFxn6QhSVtTfaukoVR/Mo0DABSkoqC33SrpTyX9Q9q3pA9I+lYa8rSkj6TtzWlf6fhDaTwAoACVntH/raS/lvRm2r9b0uWIeCPtn5O0Km2vknRWktLx4TQeAFCAaYPe9p9JuhARJ2v5wra32e613TswMFDLpwYATFDJGf37JG2yfUbSNzQ2ZfN3kpbaXpjGtEo6n7bPS1otSen4XZIulj9pRByJiFJElFpaWmb1QwAAbm7aoI+IfRHRGhFtkj4h6XsR8ReSvi/po2nYFknPpu2etK90/HsRETXtGgBQsdmso98rabftfo3NwT+V6k9JujvVd0t6dHYtAgBmY+H0Q/5fRLwg6YW0/Yqk+6cYc03Sx2rQGwCgBvhkLABkjqAHgMwR9ACQOYIeADJH0ANA5gh6AMgcQQ8AmSPoASBzBD0AZI6gB4DMEfQAkDmCHgAyR9ADQOYIegDIHEEPAJkj6AEgcwQ9AGSOoAeAzBH0AJA5gh4AMkfQA0DmCHoAyBxBDwCZI+gBIHMEPQBkjqAHgMwR9ACQOYIeADJH0ANA5gh6AMjctEFve5Ht/7T9X7Z/Zvuzqb7G9ku2+21/0/bbUr0p7fen421z+yMAAG6lkjP665I+EBHvlvQeSQ/bfkDS5yU9GRH3SRqStDWN3yppKNWfTOMAAAWZNuhjzJW025huIekDkr6V6k9L+kja3pz2lY4/ZNs16xgAMCMVzdHbXmD7J5IuSDoh6bSkyxHxRhpyTtKqtL1K0llJSseHJd09xXNus91ru3dgYGB2PwUA4KYqCvqI+N+IeI+kVkn3S/rD2b5wRByJiFJElFpaWmb7dACAm5jRqpuIuCzp+5L+SNJS2wvToVZJ59P2eUmrJSkdv0vSxZp0CwCYsUpW3bTYXpq2f0fSBkkvayzwP5qGbZH0bNruSftKx78XEVHLpgEAlVs4/RDdI+lp2ws09ofhmYj4ju2fS/qG7b+R9GNJT6XxT0n6R9v9ki5J+sQc9A0AqNC0QR8RpyR1TFF/RWPz9eX1a5I+VpPuAACzxidjASBzBD0AZI6gB4DMEfQAkDmCHgAyR9ADU2hvb5ft8Vt7e3vRLQFVI+iBMu3t7err61NDw9ivR0NDg/r6+gh71C2CHijT19cn23rsscc0MjKixx57TLbV19dXdGtAVQh6YAoHDhzQ7t27tXjxYu3evVsHDhwouiWgagQ9MIWXXnrplvtAPSHogTK2dezYMW3evFmDg4PavHmzjh07Jr4/B/WKoAfK7NixQ5LU09OjlpYW9fT0TKoD9YagB6ZgWwsXjl3zb+HChZzNo64R9ECZo0eP6vHHH9fo6KgiQqOjo3r88cd19OjRolsDquL58J0gpVIpent7i24DkDR2Nj8yMqLFixeP165evarm5mbNh98X4AbbJyOiNN04zuiBMk1NTeru7p5U6+7uVlNTU0EdAbNTyTdMAXeUzs5O7d27V5LU1dWl7u5u7d27V11dXQV3BlSHoAfKHDp0SJK0f/9+7dmzR01NTerq6hqvA/WGOXoAqFPM0QOzwNUrkROCHihz4+qVmzZt0sDAgDZt2sTVK1HXCHqgTF9fnzo6OnT69GmtXLlSp0+fVkdHB1evRN0i6IEpXLx4UYcOHdK1a9d06NAhXbx4seiWgKoR9MAUWltbtX79ejU2Nmr9+vVqbW0tuiWgagQ9MIUXX3xx0tUrX3zxxaJbAqrGOnqgzLve9S798pe/HL96pSQ1Njbq7W9/e8GdAdXhjB4o8/rrr2t0dFQPPvigfv3rX+vBBx/U6OioXn/99aJbA6pC0ANlzp49q46ODg0PD6u1tVXDw8Pq6OjQ2bNni24NqApTN8AUjh8/rhUrVozvDw4Ojk/jAPVm2jN626ttf9/2z23/zPanU3257RO2f5Xul6W6bX/Bdr/tU7bfO9c/BFBrW7duveU+UE8qmbp5Q9KeiHinpAck7bD9TkmPSno+ItZKej7tS9KHJK1Nt22SDte8a2AOrVu3Tj09PZNW3fT09GjdunVFtwZUZdqpm4h4TdJraft/bL8saZWkzZLen4Y9LekFSXtT/WsxdrW0H9peavue9DzAvHfq1Cm1t7dPWnWzbt06nTp1quDOgOrMaI7edpukDkkvSVo5Ibx/I2ll2l4laeK7VudSjaBH3SDUkZOKV93YXiLpXyT9VURMWmeWzt5ndL1j29ts99ruHRgYmMlDAQAzUFHQ227UWMj/U0T8ayr/1vY96fg9ki6k+nlJqyc8vDXVJomIIxFRiogSqxkAYO5UsurGkp6S9HJEPDHhUI+kLWl7i6RnJ9Q/mVbfPCBpmPl5AChOJXP075P0l5L6bP8k1fZL+pykZ2xvlfSqpI+nY8ckfVhSv6Srkj5V044BADNSyaqbf5fkmxx+aIrxIWnHLPsCANQIl0AAgMwR9ACQOYIeADJH0ANA5gh6AMgcQQ9MYdeuXVq0aJFsa9GiRdq1a1fRLQFVI+iBMrt27VJ3d7cOHjyokZERHTx4UN3d3YQ96pbHlr0Xq1QqRW9vb9FtAJKkRYsW6eDBg9q9e/d47YknntD+/ft17dq1AjsDJrN9MiJK044j6IHJbGtkZESLFy8er129elXNzc2aD78vwA2VBj1TN0CZpqYmdXd3T6p1d3erqampoI6A2SHogTKdnZ3as2ePbI/f9uzZo87OzqJbA6rC1A1QZsmSJRoZGXlLvbm5WVeuXCmgI2BqlU7dzOgbpoA7wcjIiJYsWaLR0VFdv35dTU1NamxsJORRt5i6AaZw5cqVScsrCXnUM6ZugDK2tWzZMl26dGm8tnz5cg0NDbHqBvMKq26AWRgaGtKaNWt0+vRprVmzRkNDQ0W3BFSNOXqgTFNTk958802dOXNG9913nySpsbFRDQ2cF6E+8S8XKNPZ2anR0dFJtdHRUZZXom4xRw+UYXkl6gVz9ECVRkZG1NbWpogYv7W1tU0Z/kA9IOiBKXz3u9+95T5QTwh6YAof/OAHb7kP1BOCHijT3NysM2fOTFpeeebMGTU3NxfdGlAVllcCZa5cuaKGhoZJyytt80Ys6hZn9ECZ9vZ2RYQ2bdqkgYEBbdq0SRGh9vb2olsDqsLySqCMba1YsUIXL15URMi27r77bg0ODnIJBMwrXL0SmIXBwcHx7YiYtA/UG6ZugJuwPekeqFcEPXATN6ZpmK5BvSPoASBz0wa97a/YvmD7pxNqy22fsP2rdL8s1W37C7b7bZ+y/d65bB6YS9u3b9fly5e1ffv2olsBZqWSM/qvSnq4rPaopOcjYq2k59O+JH1I0tp02ybpcG3aBG6/w4cPa+nSpTp8mH/GqG/TBn1E/EDSpbLyZklPp+2nJX1kQv1rMeaHkpbavqdWzQK3w4IFC2ZUB+a7aufoV0bEa2n7N5JWpu1Vks5OGHcu1d7C9jbbvbZ7BwYGqmwDqL2bTdUwhYN6Nes3Y2NsScKMlyVExJGIKEVEqaWlZbZtAABuotqg/+2NKZl0fyHVz0taPWFca6oBdeOLX/yipLeuo79RB+pNtUHfI2lL2t4i6dkJ9U+m1TcPSBqeMMUD1BXW0SMX014CwfbXJb1f0grb5yR9RtLnJD1je6ukVyV9PA0/JunDkvolXZX0qTnoGQAwA9MGfUT8+U0OPTTF2JC0Y7ZNAQBqh0/GAkDmCHoAyBxBDwCZI+gBIHMEPQBkjqAHgMwR9ACQOYIeuInGxsZJ90C94svBcUeZyfe/jo6OTrqfyeO5bALmE87ocUeJiGlvO3funPKxO3furOjxhDzmG87ogTKHDh2SJB09elTXr19XU1OTOjs7x+tAvfF8OPsolUrR29tbdBvAW9jmDB3zlu2TEVGabhxTNwCQOYIeADJH0ANA5gh6AMgcQQ8AmSPoASBzBD0AZI6gB4DMEfQAkDkugYC6tXz5cg0NDc3568zkQmjVWrZsmS5dujTnr4M7E0GPujU0NJTN5Qluxx8T3LmYugGAzBH0AJA5gh4AMkfQA0DmeDMWdSs+83vSgbuKbqMm4jO/V3QLyBhBj7rlz76e1aqbOFB0F8jVnEzd2H7Y9i9s99t+dC5eAwBQmZqf0dteIOnvJW2QdE7Sj2z3RMTPa/1aQC7rz5ctW1Z0C8jYXEzd3C+pPyJekSTb35C0WRJBj5q6HdM2fGcscjAXUzerJJ2dsH8u1QAABSjszVjb2yRtk6R77723qDZwh6lmqqeax/C/AMwnc3FGf17S6gn7rak2SUQciYhSRJRaWlrmoA3grSLittyA+WQugv5HktbaXmP7bZI+IalnDl4HAFCBmk/dRMQbtndKek7SAklfiYif1fp1AACVmZM5+og4JunYXDw3AGBmuNYNAGSOoAeAzBH0AJA5gh4AMkfQA0DmPB8+3GF7QNKrRfcBTGGFpMGimwBu4g8iYtpPnM6LoAfmK9u9EVEqug9gNpi6AYDMEfQAkDmCHri1I0U3AMwWc/QAkDnO6AEgcwQ9MAXbX7F9wfZPi+4FmC2CHpjaVyU9XHQTQC0Q9MAUIuIHki4V3QdQCwQ9AGSOoAeAzBH0AJA5gh4AMkfQA1Ow/XVJ/yHpHbbP2d5adE9AtfhkLABkjjN6AMgcQQ8AmSPoASBzBD0AZI6gB4DMEfQAkDmCHgAyR9ADQOb+DyVujgvqTcEUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      0.0000\n",
       "0.1      7.5500\n",
       "0.2      7.8542\n",
       "0.3      8.0500\n",
       "0.4     10.5000\n",
       "0.5     14.4542\n",
       "0.6     21.6792\n",
       "0.7     27.0000\n",
       "0.8     39.6875\n",
       "0.9     77.9583\n",
       "1.0    512.3292\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove outliers in Fare values\n",
    "# Get relevant percentiles and see their distribution\n",
    "df['Fare'].quantile([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0896"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate 25th and 75th percentile, and the InterQuartile Range (IQR)\n",
    "fare_q25, fare_q75 = np.percentile(df['Fare'], 25), np.percentile(df['Fare'], 75)\n",
    "fare_iqr = fare_q75 - fare_q25\n",
    "fare_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower: 0, Upper: 261.896\n"
     ]
    }
   ],
   "source": [
    "# Find the lower and upper limits\n",
    "cutoff = fare_iqr * 10 # 10 is too high a value. Usually, values above or below 1.5 times IQR are deemed acceptable\n",
    "lower, upper = max(fare_q25 - cutoff, 0), fare_q75 + cutoff\n",
    "print(\"Lower: {}, Upper: {}\".format(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Mabel Helen</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Mark</td>\n",
       "      <td>male</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Susan Parker \"Suzette\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                   Name  \\\n",
       "27            28         0       1         Fortune, Mr. Charles Alexander   \n",
       "88            89         1       1             Fortune, Miss. Mabel Helen   \n",
       "258          259         1       1                       Ward, Miss. Anna   \n",
       "311          312         1       1             Ryerson, Miss. Emily Borie   \n",
       "341          342         1       1         Fortune, Miss. Alice Elizabeth   \n",
       "438          439         0       1                      Fortune, Mr. Mark   \n",
       "679          680         1       1     Cardeza, Mr. Thomas Drake Martinez   \n",
       "737          738         1       1                 Lesurer, Mr. Gustave J   \n",
       "742          743         1       1  Ryerson, Miss. Susan Parker \"Suzette\"   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket      Fare            Cabin Embarked  \n",
       "27     male  19.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "88   female  23.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "258  female  35.0      0      0  PC 17755  512.3292              NaN        C  \n",
       "311  female  18.0      2      2  PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "341  female  24.0      3      2     19950  263.0000      C23 C25 C27        S  \n",
       "438    male  64.0      1      4     19950  263.0000      C23 C25 C27        S  \n",
       "679    male  36.0      0      1  PC 17755  512.3292      B51 B53 B55        C  \n",
       "737    male  35.0      0      0  PC 17755  512.3292             B101        C  \n",
       "742  female  21.0      2      2  PC 17608  262.3750  B57 B59 B63 B66        C  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe Outliers\n",
    "df[(df['Fare'] < lower) | (df['Fare'] > upper)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On deeper analysis, the outlier fares seem to be valid and belonging to 3 ticket numbers. Let's keep all Fare values and not remove any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/numpy/lib/function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n",
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1872: RuntimeWarning: invalid value encountered in less_equal\n",
      "  wiskhi = np.compress(x <= hival, x)\n",
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1879: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  wisklo = np.compress(x >= loval, x)\n",
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1887: RuntimeWarning: invalid value encountered in less\n",
      "  np.compress(x < stats['whislo'], x),\n",
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1888: RuntimeWarning: invalid value encountered in greater\n",
      "  np.compress(x > stats['whishi'], x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1134af7b8>,\n",
       "  <matplotlib.lines.Line2D at 0x1134afc50>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x11394e0b8>,\n",
       "  <matplotlib.lines.Line2D at 0x11394e4e0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1134af390>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x11394e908>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x11394ed30>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age** seems to be distributed well, so let us not eliminate any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex\n",
    "\n",
    "Change 'female' and 'male' values to 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sex(df):\n",
    "    df['Sex'].replace({'female':0,'male':1},inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deck\n",
    "\n",
    "Change A-G decks with numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_deck(df):\n",
    "    df['Deck'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], [0, 1, 2, 3, 4, 5, 6, 7], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous columns\n",
    "\n",
    "Drop **PassengerId**, **Ticket** and **Name** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_unnecessary_columns(df):\n",
    "    df = df.drop(['Name', 'PassengerId', 'Ticket'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(df):\n",
    "    df = clean_cabin(df)\n",
    "    df = clean_embarked(df)\n",
    "    df = clean_age(df)\n",
    "    df = clean_sex(df)\n",
    "    df = clean_deck(df)\n",
    "    df = clean_unnecessary_columns(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Deck\n",
       "0         0       3    1  22.0      1      0   7.2500         0     6\n",
       "1         1       1    0  38.0      1      0  71.2833         1     2\n",
       "2         1       3    0  26.0      0      0   7.9250         0     6\n",
       "3         1       1    0  35.0      1      0  53.1000         0     2\n",
       "4         0       3    1  35.0      0      0   8.0500         0     6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data and target values\n",
    "y = df['Survived']\n",
    "df = df.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "* https://machinelearningmastery.com/feature-selection-machine-learning-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.11295582e+01 9.26007474e+01 2.16936333e+01 2.64263585e+00\n",
      " 9.98961888e+00 4.52407258e+03 1.12413776e+01 3.41879218e+01]\n",
      "[[ 3.      1.      7.25    6.    ]\n",
      " [ 1.      0.     71.2833  2.    ]\n",
      " [ 3.      0.      7.925   6.    ]\n",
      " [ 1.      0.     53.1     2.    ]\n",
      " [ 3.      1.      8.05    6.    ]]\n"
     ]
    }
   ],
   "source": [
    "kbest = SelectKBest(score_func=chi2, k=4)\n",
    "kbest_fit = kbest.fit(df, y)\n",
    "\n",
    "# Summarize Scores\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "print(kbest_fit.scores_)\n",
    "\n",
    "features = kbest_fit.transform(df)\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which features were chosen\n",
    "mask = kbest_fit.get_support() #list of booleans\n",
    "univariate_new_features = [] # The list of your K best features\n",
    "feature_names = list(df.columns.values)\n",
    "\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        univariate_new_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Fare', 'Deck']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "univariate_new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 4\n",
      "Selected Features: [ True  True False  True False False  True False]\n",
      "Feature Ranking: [1 1 4 1 3 5 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "rfe = RFE(linear_model, 4)\n",
    "rfe_fit = rfe.fit(df, y)\n",
    "print(\"Num Features: %d\" % (rfe_fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (rfe_fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (rfe_fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which features were chosen\n",
    "mask = rfe_fit.support_ #list of booleans\n",
    "recursive_new_features = [] # The list of your K best features\n",
    "feature_names = list(df.columns.values)\n",
    "\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        recursive_new_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'SibSp', 'Embarked']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recursive_new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [9.26416105e-01 7.18381166e-02 8.33508603e-04 4.49437840e-04]\n",
      "Components: [[-9.27635955e-03 -1.74827354e-03  2.64189287e-02  3.50431539e-03\n",
      "   3.48325718e-03  9.99463777e-01  7.96631154e-04 -1.61258860e-02]\n",
      " [-1.53699385e-02  2.70250566e-03  9.98958042e-01 -1.83935673e-02\n",
      "  -1.11909643e-02 -2.68532871e-02  9.83698722e-04 -2.55668634e-02]\n",
      " [ 3.60608374e-01 -7.32271819e-03  3.44080549e-02  2.21753945e-01\n",
      "   1.28816829e-01  1.56259566e-02  2.67751283e-02  8.95541400e-01]\n",
      " [-7.53992437e-02 -5.85935476e-02  1.31987956e-02  8.79624567e-01\n",
      "   3.87838953e-01 -9.40887516e-03 -9.06071413e-02 -2.41352294e-01]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca_fit = pca.fit(df, y)\n",
    "\n",
    "print(\"Explained Variance: %s\" % (pca_fit.explained_variance_ratio_))\n",
    "print(\"Components:\", pca_fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08013477 0.26599251 0.24734799 0.04252159 0.04540781 0.21612114\n",
      " 0.03651952 0.06595466]\n"
     ]
    }
   ],
   "source": [
    "extra_trees_model = ExtraTreesClassifier()\n",
    "extra_trees_model.fit(df, y)\n",
    "\n",
    "print(extra_trees_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Training and Test data\n",
    "\n",
    "Split data simplistically into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/subhashb/.pyenv/versions/3.6.5/envs/100-days/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94  6]\n",
      " [27 51]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.94      0.85       100\n",
      "          1       0.89      0.65      0.76        78\n",
      "\n",
      "avg / total       0.83      0.81      0.81       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks - with selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_univariate_features = df[univariate_new_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_univariate_features, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.95      0.86       100\n",
      "          1       0.91      0.67      0.77        78\n",
      "\n",
      "avg / total       0.84      0.83      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "pred = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recursive_features = df[recursive_new_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_recursive_features, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.96      0.85       100\n",
      "          1       0.92      0.62      0.74        78\n",
      "\n",
      "avg / total       0.83      0.81      0.80       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30))\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "pred = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "df_pca = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77       100\n",
      "          1       0.75      0.50      0.60        78\n",
      "\n",
      "avg / total       0.72      0.71      0.70       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30), random_state=21)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "pred = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n",
      "0.7303370786516854\n",
      "0.7865168539325843\n",
      "0.8314606741573034\n",
      "0.7415730337078652\n",
      "0.797752808988764\n",
      "0.7640449438202247\n",
      "0.7865168539325843\n",
      "0.8539325842696629\n",
      "0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(30,30,30), random_state=21)\n",
    "\n",
    "for train_indices, test_indices in kf.split(df):\n",
    "    clf.fit(df.iloc[train_indices], y.iloc[train_indices])\n",
    "    print(clf.score(df.iloc[test_indices], y.iloc[test_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_df = clean_all(test_df)\n",
    "predictions = clf.predict(cleaned_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.83</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  Fare  Embarked  Deck\n",
       "0       3    1 34.50      0      0  7.83         2     5\n",
       "1       3    0 47.00      1      0  7.00         0     4\n",
       "2       2    1 62.00      0      0  9.69         2     4\n",
       "3       3    1 27.00      0      0  8.66         0     4\n",
       "4       3    0 22.00      1      1 12.29         0     6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('survival.csv', 'w') as output_file:\n",
    "    csv_out = csv.writer(output_file)\n",
    "    csv_out.writerow(['PassengerId', 'Survived'])\n",
    "    for i, row in cleaned_test_df.iterrows():\n",
    "        csv_out.writerow((test_df.iloc[i]['PassengerId'], predictions[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
